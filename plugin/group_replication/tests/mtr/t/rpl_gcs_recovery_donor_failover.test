# Recovery donor failover test
# This test focus on the failover mechanism where a joiner changes it's donor
# whenever the one in use leaves the group while recovery is happening.
#
# To test this, a new node is started but recovery blocked. While at this state
# the donor is killed, forcing the joiner to change to a new one. As there is
# no donor identification as of now, we just unblock and check that recovery
# was successful

--source include/have_debug.inc
--source include/have_group_replication_plugin.inc
--let $group_replication_group_name= 55d07150-9a4d-11e3-a5e2-0800200c9a66
--let $rpl_skip_group_replication_start= 1
--let $rpl_server_count= 3
--source include/master-slave.inc

--echo #
--echo # Setup a new 2 node cluster
--echo #

--connection server1
SET SESSION sql_log_bin= 0;
call mtr.add_suppression(".*Error when configuring the group recovery connection *.*");
SET SESSION sql_log_bin= 1;

--source include/start_group_replication.inc

--let $group_replication_number_of_members= 1
--source ../inc/rpl_group_replication_wait_for_number_of_members.inc

#insert some data
CREATE TABLE t1 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;
INSERT INTO t1 VALUES (1);

#record the executed GTIDs at this point
--let $first_donor_gtid= `SELECT @@GLOBAL.GTID_EXECUTED`

--connection server2
SET SESSION sql_log_bin= 0;
call mtr.add_suppression(".*Error when configuring the group recovery connection *.*");
SET SESSION sql_log_bin= 1;

--source include/start_group_replication.inc

--let $group_replication_number_of_members= 2
--source ../inc/rpl_group_replication_wait_for_number_of_members.inc

--echo #
--echo # Start recovery on a new node and kill the donor
--echo #

SET @debug_save= @@GLOBAL.DEBUG;

--connection server3
SET SESSION sql_log_bin= 0;
call mtr.add_suppression(".*Error when configuring the group recovery connection *.*");
SET SESSION sql_log_bin= 1;

SET @@GLOBAL.DEBUG='d,recovery_thread_wait';
SET GLOBAL group_replication_group_name= "55d07150-9a4d-11e3-a5e2-0800200c9a66";
START GROUP_REPLICATION;

--let $group_replication_member_state= RECOVERING
--source ../inc/rpl_group_replication_wait_for_member_state.inc

#The first node is always the donor under the current algorithm
--echo # Stop gcs replication on node 1 making it leave the cluster
--connection server1
--source include/stop_group_replication.inc

--echo # Unblock recovery and watch the node go online despite the donor exit
--connection server3
SET @@GLOBAL.DEBUG= @debug_save;
SET DEBUG_SYNC= "now SIGNAL signal.recovery_continue";

--let $group_replication_member_state= ONLINE
--source ../inc/rpl_group_replication_wait_for_member_state.inc

--let $assert_text= On the recovered node, the table should exist and have 1 elements;
--let $assert_cond= [select count(*) from t1] = 1;
--source include/assert.inc

--let $assert_text= On the recovered node, the executed GTID should be the same as on server 1
--let $assert_cond= "[SELECT @@GLOBAL.GTID_EXECUTED]" = "$first_donor_gtid";
--source include/assert.inc

--echo #
--echo # Cleaning up
--echo #

--connection server1
--source include/start_group_replication.inc

DROP TABLE t1;

--source include/rpl_end.inc
