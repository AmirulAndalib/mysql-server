# This test intends to prove that nodes can survive reset master commands.
# These commands end up causing the nodes to purge their relay logs

--source include/have_gcs_replication_plugin.inc
--let $gcs_group_name= c90c3c80-fde4-11e3-a3ac-0800200c9a66
#The time we wait for things to appear on both nodes.
#TODO: replace by a sync call
--let $sync_wait_time= 2

--connection server1
--source include/install_gcs_replication.inc

--echo #Test a reset command before start.
RESET MASTER;

--source include/start_gcs_replication.inc

--connection server2
--source include/install_gcs_replication.inc
--source include/start_gcs_replication.inc

--echo #Create a table and insert some data
--connection server1
CREATE TABLE t1 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;

--sleep $sync_wait_time # sleep for the table to appear on node 2

--connection server2
INSERT INTO t1 VALUES (1);

--connection server1
INSERT INTO t1 VALUES (2);

--connection server2
INSERT INTO t1 VALUES (3);

--sleep $sync_wait_time # sleep for the gtid to stabilize

--echo #Both nodes must have the same GTID set
--let $server_count=2
while ($server_count)
{
  --connection server$server_count
  --let $assert_text= On node $server_count, all executed GTID should belong to the cluster
  --let $assert_cond= "[SELECT @@GLOBAL.GTID_EXECUTED]" = "c90c3c80-fde4-11e3-a3ac-0800200c9a66:1-4";
  --source include/assert.inc
  --dec $server_count
}

--echo #Stop and reset both nodes

--connection server1
--source include/stop_gcs_replication.inc
RESET MASTER;

--connection server2
--source include/stop_gcs_replication.inc
RESET MASTER;

--echo #Restart both nodes

--source include/start_gcs_replication.inc

--connection server1

--source include/start_gcs_replication.inc

--echo #Both nodes must have an empty gtid set
--let $server_count=2
while ($server_count)
{
  --connection server$server_count
  --let $assert_text= On node $server_count, all executed GTID should belong to the cluster
  --let $assert_cond= "[SELECT @@GLOBAL.GTID_EXECUTED]" = "";
  --source include/assert.inc
  --dec $server_count
}

--echo #Insert some data to test that the cluster is still running

INSERT INTO t1 VALUES (4);

--connection server2

INSERT INTO t1 VALUES (5);

--connection server1

--sleep $sync_wait_time #sleep for the inserts to appear on both nodes

--let $server_count=2
while ($server_count)
{
  --connection server$server_count
  --let $assert_text= On all nodes, the table should exist and have 5 elements
  --let $assert_cond= [select count(*) from t1] = 5;
  --source include/assert.inc
  --dec $server_count
}

DROP TABLE t1;
--sleep $sync_wait_time #sleep for the drop to reach both nodes

--source include/stop_gcs_replication.inc
--source include/uninstall_gcs_replication.inc

--connection server2
--source include/stop_gcs_replication.inc
--source include/uninstall_gcs_replication.inc
